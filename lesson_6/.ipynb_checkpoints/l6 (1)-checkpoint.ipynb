{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4IgnCZuOs4Fk"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-9AAwHnPr7od"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "data_r = zipfile.ZipFile('train.zip', 'r')\n",
    "data_r.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QNsrrl6VsU_F"
   },
   "outputs": [],
   "source": [
    "data_r = zipfile.ZipFile('test.zip', 'r')\n",
    "data_r.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SISIsfkxs5l7"
   },
   "outputs": [],
   "source": [
    "def download_data(path):\n",
    "  data = []\n",
    "  for path_image in sorted(os.listdir(path=path)):\n",
    "    image = Image.open(path + path_image) #Открываем изображение.\n",
    "    data.append(np.array(image)) #Загружаем пиксели.\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aVma1xbgs2jF"
   },
   "outputs": [],
   "source": [
    "X_train = download_data(r\"train/images/\")\n",
    "Y_train = download_data(r\"train/masks/\")\n",
    "X_test = download_data(r\"test/images/\")\n",
    "Y_test = download_data(r\"test/masks/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X_ayb_KzU-sY"
   },
   "outputs": [],
   "source": [
    "def resize(input_image, input_mask):\n",
    "   input_image = tf.image.resize(input_image, (128, 128), method=\"nearest\")\n",
    "   input_mask = tf.image.resize(input_mask, (128, 128), method=\"nearest\")\n",
    "   return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "K4OM3WxRVBCF"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = resize(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "X8Tl2Ee4VH9l"
   },
   "outputs": [],
   "source": [
    "X_test, Y_test = resize(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "5fOK8rmVt0ak",
    "outputId": "75649d54-0e0c-4e82-86e8-d3faa9f4cddb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[177, 181, 184],\n",
       "        [205, 209, 212],\n",
       "        [219, 223, 226],\n",
       "        ...,\n",
       "        [226, 229, 246],\n",
       "        [230, 233, 250],\n",
       "        [243, 246, 255]],\n",
       "\n",
       "       [[217, 221, 224],\n",
       "        [244, 248, 251],\n",
       "        [252, 255, 255],\n",
       "        ...,\n",
       "        [229, 232, 247],\n",
       "        [217, 220, 237],\n",
       "        [208, 211, 228]],\n",
       "\n",
       "       [[234, 238, 241],\n",
       "        [252, 255, 255],\n",
       "        [250, 254, 255],\n",
       "        ...,\n",
       "        [240, 242, 255],\n",
       "        [237, 239, 254],\n",
       "        [225, 228, 243]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[201, 198, 209],\n",
       "        [223, 217, 229],\n",
       "        [221, 215, 225],\n",
       "        ...,\n",
       "        [241, 234, 224],\n",
       "        [255, 250, 240],\n",
       "        [255, 251, 241]],\n",
       "\n",
       "       [[194, 191, 202],\n",
       "        [217, 211, 223],\n",
       "        [223, 217, 227],\n",
       "        ...,\n",
       "        [222, 215, 205],\n",
       "        [230, 223, 213],\n",
       "        [223, 216, 206]],\n",
       "\n",
       "       [[212, 209, 220],\n",
       "        [197, 191, 203],\n",
       "        [179, 173, 183],\n",
       "        ...,\n",
       "        [240, 233, 223],\n",
       "        [255, 247, 238],\n",
       "        [254, 245, 236]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrG-ykmIuOcj",
    "outputId": "33c47cf2-ad24-4014-a890-d4b4184d77e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCXQpzyZt6Ui",
    "outputId": "599cdd4b-b159-4092-a3ec-ed64958f4ae3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZcmg1WQuTIi",
    "outputId": "12985c79-0d80-422c-e911-f69be60e3bd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "796"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tI-7mKvJuixR",
    "outputId": "4105938f-2c23-4195-aa30-058272436cd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([132,  41, 246, 255], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMeBQA_suYnq",
    "outputId": "85185bf6-0107-426f-b3a6-8aaeb8ad71ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KC2UWCMGuwz4"
   },
   "outputs": [],
   "source": [
    "palette = {0 : (60, 16, 152), # Building\n",
    "           1 : (132, 41, 246), # Land\n",
    "           2 : (110, 193, 228), # Road\n",
    "           3 : (254, 221, 58), # Vegetation\n",
    "           4 : (226, 169, 41), # Water\n",
    "           5 : (155, 155, 155)} # Unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XJGCusxYvIOi"
   },
   "outputs": [],
   "source": [
    "invert_palette = {v: k for k, v in palette.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "u2xjpP2VvUiY"
   },
   "outputs": [],
   "source": [
    "# сегментация нейронной сети в RGB изображение\n",
    "def convert_to_color(arr_2d, palette=palette):\n",
    "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
    "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = arr_2d == c\n",
    "        arr_3d[m] = i\n",
    "\n",
    "    return arr_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7uyEDYdTv81I"
   },
   "outputs": [],
   "source": [
    "def convert_from_color(arr_3d, palette=invert_palette):\n",
    "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
    "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.int8) # принадлежность каждого пикселя классу\n",
    "    min_distance = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.float32)+1000 # расстояние до ближайшего класса для пикселей\n",
    "    for c, i in palette.items():\n",
    "      distance = np.sum((arr_3d - np.array(c).reshape(1, 1, 3))**2, axis=-1)**(1/2) # ищем расстояние для каждого пикселя до проверяемого класса по евклиду рас-ие\n",
    "      condition = min_distance > distance # поиск элементов меньше min_distance\n",
    "      min_distance[condition] = distance[condition] # замена дистанции найденных элементов\n",
    "      arr_2d[condition] = i # замена класса найденных элементов\n",
    "\n",
    "    for c, i in palette.items():\n",
    "      m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
    "      arr_2d[m] = i\n",
    "\n",
    "    arr_2d = arr_2d.tolist()\n",
    "    for i in range(len(arr_2d)):\n",
    "      for j in range(len(arr_2d[0])):\n",
    "        label = [0, 0, 0, 0, 0, 0]\n",
    "        label[arr_2d[i][j]] = 1\n",
    "        arr_2d[i][j] = label\n",
    "    arr_2d = np.array(arr_2d)\n",
    "\n",
    "    return arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "QRH5wFPIxysn"
   },
   "outputs": [],
   "source": [
    "X_train_pred = np.array(X_train).reshape([7, 128, 128, 3])/255\n",
    "X_test_pred = np.array(X_test).reshape([2, 128, 128, 3])/255\n",
    "Y_train_pred = []\n",
    "for i in range(len(Y_train)):\n",
    "  Y_train_pred.append(convert_from_color(Y_train[i][:, :, :3]))\n",
    "Y_train_pred = np.array(Y_train_pred)\n",
    "Y_test_pred = []\n",
    "for i in range(len(Y_test)):\n",
    "  Y_test_pred.append(convert_from_color(Y_test[i][:, :, :3]))\n",
    "Y_test_pred = np.array(Y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "S6xEqOpzyK4m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yw4chFWMT5JY"
   },
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "   # Conv2D then ReLU activation\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "   # Conv2D then ReLU activation\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "71aa1kS9UdpV"
   },
   "outputs": [],
   "source": [
    "def upsample_block(x, conv_features, n_filters):\n",
    "   # upsample\n",
    "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "   # concatenate\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   # dropout\n",
    "   x = layers.Dropout(0.3)(x)\n",
    "   # Conv2D twice with ReLU activation\n",
    "   x = double_conv_block(x, n_filters)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6-0SlpZRT9JP"
   },
   "outputs": [],
   "source": [
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   p = layers.Dropout(0.3)(p)\n",
    "   return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FVTEl4lXUG_A"
   },
   "outputs": [],
   "source": [
    "def build_unet_model():\n",
    "   # inputs\n",
    "   inputs = layers.Input(shape=(128,128,3))\n",
    "   # encoder: contracting path - downsample\n",
    "   # 1 - downsample\n",
    "   f1, p1 = downsample_block(inputs, 64)\n",
    "   # 2 - downsample\n",
    "   f2, p2 = downsample_block(p1, 128)\n",
    "   # 3 - downsample\n",
    "   f3, p3 = downsample_block(p2, 256)\n",
    "   # 4 - downsample\n",
    "   f4, p4 = downsample_block(p3, 512)\n",
    "   # 5 - bottleneck\n",
    "   bottleneck = double_conv_block(p4, 1024)\n",
    "   # decoder: expanding path - upsample\n",
    "   # 6 - upsample\n",
    "   u6 = upsample_block(bottleneck, f4, 512)\n",
    "   # 7 - upsample\n",
    "   u7 = upsample_block(u6, f3, 256)\n",
    "   # 8 - upsample\n",
    "   u8 = upsample_block(u7, f2, 128)\n",
    "   # 9 - upsample\n",
    "   u9 = upsample_block(u8, f1, 64)\n",
    "   # outputs\n",
    "   outputs = layers.Conv2D(6, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
    "   # unet model with Keras Functional API\n",
    "   unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "   return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Z3otCMTXUVsr"
   },
   "outputs": [],
   "source": [
    "unet_model = build_unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bR8a8e6KVh86"
   },
   "outputs": [],
   "source": [
    "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAuxCsFsVlyZ",
    "outputId": "0cf5ddd9-2c74-4dc0-fff2-dffd166aab5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4954 - accuracy: 0.4248 - val_loss: 5.4987 - val_accuracy: 0.6051\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.5466 - accuracy: 0.6272 - val_loss: 1.0514 - val_accuracy: 0.6051\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0806 - accuracy: 0.6272 - val_loss: 1.0849 - val_accuracy: 0.6051\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0785 - accuracy: 0.6268 - val_loss: 1.1427 - val_accuracy: 0.6047\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1362 - accuracy: 0.6257 - val_loss: 1.1566 - val_accuracy: 0.6041\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1563 - accuracy: 0.6257 - val_loss: 1.1342 - val_accuracy: 0.6043\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1423 - accuracy: 0.6282 - val_loss: 1.0918 - val_accuracy: 0.6048\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1071 - accuracy: 0.6281 - val_loss: 1.0485 - val_accuracy: 0.6050\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0688 - accuracy: 0.6285 - val_loss: 1.0134 - val_accuracy: 0.6052\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0375 - accuracy: 0.6307 - val_loss: 0.9890 - val_accuracy: 0.6052\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = unet_model.fit(X_train_pred, Y_train_pred,  epochs=10, validation_data = (X_test_pred, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cl1UPcFfyhAs"
   },
   "outputs": [],
   "source": [
    "# def unet_model(image_size, output_classes):\n",
    "\n",
    "#     #Входной слой\n",
    "#     input_layer = Input(shape=image_size + (3,))\n",
    "#     conv_1 = Conv2D(64, 4,\n",
    "#                                     activation=LeakyReLU(),\n",
    "#                                     strides=2, padding='same',\n",
    "#                                     kernel_initializer='glorot_normal',\n",
    "#                                     use_bias=False)(input_layer)\n",
    "#     #Сворачиваем\n",
    "#     conv_1_1 = Conv2D(128, 4,\n",
    "#                                       activation=LeakyReLU(),\n",
    "#                                       strides=2,\n",
    "#                                       padding='same',\n",
    "#                                       kernel_initializer='glorot_normal',\n",
    "#                                       use_bias=False)(conv_1)\n",
    "#     batch_norm_1 = BatchNormalization()(conv_1_1)\n",
    "\n",
    "#     #2\n",
    "#     conv_2 = Conv2D(256, 4,\n",
    "#                                     activation=LeakyReLU(),\n",
    "#                                     strides=2,\n",
    "#                                     padding='same',\n",
    "#                                     kernel_initializer='glorot_normal',\n",
    "#                                     use_bias=False)(batch_norm_1)\n",
    "#     batch_norm_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "#     #3\n",
    "#     conv_3 = Conv2D(512, 4,\n",
    "#                                     activation=LeakyReLU(),\n",
    "#                                     strides=2,\n",
    "#                                     padding='same',\n",
    "#                                     kernel_initializer='glorot_normal',\n",
    "#                                     use_bias=False)(batch_norm_2)\n",
    "#     batch_norm_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "#     #4\n",
    "#     conv_4 = Conv2D(512, 4,\n",
    "#                                     activation=LeakyReLU(),\n",
    "#                                     strides=2,\n",
    "#                                     padding='same',\n",
    "#                                     kernel_initializer='glorot_normal',\n",
    "#                                     use_bias=False)(batch_norm_3)\n",
    "#     batch_norm_4 = BatchNormalization()(conv_4)\n",
    "\n",
    "#     #5\n",
    "#     conv_5 = Conv2D(512, 4,\n",
    "#                                     activation=LeakyReLU(),\n",
    "#                                     strides=2,\n",
    "#                                     padding='same',\n",
    "#                                     kernel_initializer='glorot_normal',\n",
    "#                                     use_bias=False)(batch_norm_4)\n",
    "#     batch_norm_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "#     #6\n",
    "#     conv_6 = Conv2D(512, 4,\n",
    "#                                     activation=LeakyReLU(),\n",
    "#                                     strides=2,\n",
    "#                                     padding='same',\n",
    "#                                     kernel_initializer='glorot_normal',\n",
    "#                                     use_bias=False)(batch_norm_5)\n",
    "#     ch, cw = get_crop_shape(conv_5,conv_5)\n",
    "#       #Разворачиваем\n",
    "#     #1\n",
    "#     up_1 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
    "#                                                                           padding='same',\n",
    "#                                                                           kernel_initializer='glorot_normal',\n",
    "#                                                                           use_bias=False)(conv_6), conv_5])\n",
    "#     batch_up_1 = BatchNormalization()(up_1)\n",
    "\n",
    "#     #Добавим Dropout от переобучения\n",
    "#     batch_up_1 = Dropout(0.25)(batch_up_1)\n",
    "\n",
    "#     #2\n",
    "#     up_2 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
    "#                                                                           padding='same',\n",
    "#                                                                           kernel_initializer='glorot_normal',\n",
    "#                                                                           use_bias=False)(batch_up_1), conv_4])\n",
    "#     batch_up_2 = BatchNormalization()(up_2)\n",
    "#     batch_up_2 = Dropout(0.25)(batch_up_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     #3\n",
    "#     up_3 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
    "#                                                                           padding='same',\n",
    "#                                                                           kernel_initializer='glorot_normal',\n",
    "#                                                                           use_bias=False)(batch_up_2), conv_3])\n",
    "#     batch_up_3 = BatchNormalization()(up_3)\n",
    "#     batch_up_3 = Dropout(0.25)(batch_up_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     #4\n",
    "#     up_4 = Concatenate()([Conv2DTranspose(256, 4, activation='relu', strides=2,\n",
    "#                                                                           padding='same',\n",
    "#                                                                           kernel_initializer='glorot_normal',\n",
    "#                                                                           use_bias=False)(batch_up_3), conv_2])\n",
    "#     batch_up_4 = BatchNormalization()(up_4)\n",
    "\n",
    "\n",
    "#     #5\n",
    "#     up_5 = Concatenate()([Conv2DTranspose(128, 4, activation='relu', strides=2,\n",
    "#                                                                           padding='same',\n",
    "#                                                                           kernel_initializer='glorot_normal',\n",
    "#                                                                           use_bias=False)(batch_up_4), conv_1_1])\n",
    "#     batch_up_5 = BatchNormalization()(up_5)\n",
    "\n",
    "\n",
    "#     #6\n",
    "#     up_6 = Concatenate()([Conv2DTranspose(64, 4, activation='relu', strides=2,\n",
    "#                                                                           padding='same',\n",
    "#                                                                           kernel_initializer='glorot_normal',\n",
    "#                                                                           use_bias=False)(batch_up_5), conv_1])\n",
    "#     batch_up_6 = BatchNormalization()(up_6)\n",
    "\n",
    "\n",
    "#     #Выходной слой\n",
    "#     output_layer = Conv2DTranspose(output_classes, 4, activation='sigmoid', strides=2,\n",
    "#                                                    padding='same',\n",
    "#                                                    kernel_initializer='glorot_normal')(batch_up_6)\n",
    "\n",
    "#     model = Model(inputs=input_layer, outputs=output_layer)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "K4RZng-j1lSx"
   },
   "outputs": [],
   "source": [
    "from keras.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fa1P0qSr1uAI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "Gip9dYsNBDm_",
    "outputId": "fc3961ed-f85f-43f2-9591-5ca573a67190"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"U-Net\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=796>, <tf.Tensor: shape=(), dtype=int32, numpy=644>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16644\\3776113341.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m796\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m644\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    220\u001b[0m             \u001b[1;34mf'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;34mf\" but it received {len(inputs)} input tensors. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"U-Net\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=796>, <tf.Tensor: shape=(), dtype=int32, numpy=644>]"
     ]
    }
   ],
   "source": [
    "model = unet_model((796,644), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jyr6zavFBDdH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "yAQmdfxZ1sLz"
   },
   "outputs": [],
   "source": [
    "#Функция для подсчёта DICE коэффициента\n",
    "def dice_coef(y_pred, y_true):\n",
    "    y_pred = tf.unstack(y_pred, axis=3)\n",
    "    y_true = tf.unstack(y_true, axis=3)\n",
    "    dice_summ = 0\n",
    "\n",
    "    for i, (a_y_pred, b_y_true) in enumerate(zip(y_pred, y_true)):\n",
    "        dice_calculate = (2 * tf.math.reduce_sum(a_y_pred * b_y_true) + 1) /\\\n",
    "         (tf.math.reduce_sum(a_y_pred + b_y_true) + 1)\n",
    "\n",
    "        dice_summ += dice_calculate\n",
    "    avg_dice = dice_summ/CLASSES\n",
    "    return avg_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "L9WoQKnD1bRr"
   },
   "outputs": [],
   "source": [
    "#Функция для подсчета DICE loss\n",
    "def dice_loss(y_pred, y_true):\n",
    "    d_loss = 1 - dice_coef(y_pred, y_true)\n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "j9lqcvoYzTAE"
   },
   "outputs": [],
   "source": [
    "# Binary crossentropy + 0.25 * DICE\n",
    "def dice_bce_loss(y_pred, y_true):\n",
    "    total_loss = 0.25 * dice_loss(y_pred, y_true) + keras.losses.binary_crossentropy(y_pred, y_true)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
